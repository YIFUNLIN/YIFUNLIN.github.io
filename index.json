[{"categories":["Knative","kustomization"],"contents":"簡介： ","permalink":"https://yifunlin.github.io/blog/knative_kustomization/","tags":null,"title":"Knative 和 kustomization 介紹"},{"categories":["Infra"],"contents":"簡介： Terraform 是什麼？白話來說，它就是利用宣告式的方式，把所有需要的雲端資源，像是 VM、K8s cluster、網路設定，全部寫成程式碼方式去進行部署，可以省去學習各種雲端服務商所提供UI的時間，大幅增進開發效率！\n我有將這篇投稿至我們 LINE 官方的 Blog 進行分享，快來看看吧！\n","permalink":"https://yifunlin.github.io/blog/terraform/","tags":["Kubernetes","Terraform"],"title":"從無到有：用 Terraform 與 GitOps 打造企業級 n8n 自動化流程引擎"},{"categories":["Kubernetes"],"contents":"在了解了 Kubernetes 的基礎架構後，這次我們來探討一個建立在其之上的強大 Serverless 框架：Knative。它將開發者從繁瑣的基礎設施管理中解放出來，專注於程式碼本身。\n什麼是 Knative？ Knative 是一個開源的 Kubernetes 附加元件 (Add-on)，用於建構、部署和管理現代化的 Serverless 工作負載。它並非要取代 Kubernetes，而是擴展 Kubernetes，提供了一組更高階的抽象化原語 (Primitives)，旨在標準化和簡化 Serverless 應用程式的開發與部署流程。\n其核心價值主張是：讓開發者只關心業務邏輯，而將服務的自動擴展 (Auto-scaling)、網路路由和事件觸發等複雜性交給平台處理。\nKnative 的核心組件 Knative 主要由兩個獨立且可插拔的核心組件構成：\n1. Serving (服務供給) Knative Serving 的目標是部署和服務 Serverless 應用程式和函式。它最引人注目的特性是請求驅動 (Request-Driven) 的計算模型，能夠根據流量需求自動擴展 Pod 數量，甚至在沒有流量時縮容至零 (Scale to Zero)，從而極大地節省了運算資源成本。\n主要特性：\n快速部署與版本管理: 每次對應用程式的程式碼或配置進行更改時，都會創建一個不可變的修訂版本 (Revision)，方便進行版本追蹤和快速回滾。 流量分割 (Traffic Splitting): 能夠精確控制流向不同修訂版本的流量比例，輕鬆實現金絲雀部署 (Canary Deployments) 和藍綠部署 (Blue/Green Deployments)。 基於請求的自動擴展: 內建 KPA (Knative Pod Autoscaler) 元件，可根據每秒處理的併發請求數來自動增減 Pod 實例。 核心資源 (CRDs):\nService (ksvc): 這是開發者主要操作的頂層資源，它自動管理一個應用的 Route 和 Configuration，簡化了部署流程。 Route: 負責將網路端點 (URL) 映射到一個或多個 Revision，並定義流量分配策略。 Configuration: 定義了應用程式的期望狀態，包括容器映像檔、環境變數等。每次 Configuration 的變更都會觸發一個新的 Revision。 Revision: Configuration 的一個不可變的時間點快照。每個 Revision 都代表了一份特定的程式碼和配置組合。 2. Eventing (事件驅動) Knative Eventing 提供了一套標準化的基礎設施，用於建構事件驅動架構。它旨在實現服務間的鬆耦合 (Loosely Coupled)，讓事件的生產者 (Producers) 和消費者 (Consumers) 彼此獨立，無需直接感知對方的存在。\n工作流程： 它採用了發布/訂閱 (Publish/Subscribe) 模型，事件從來源 (Source) 進入系統，被發送到一個稱為代理 (Broker) 的事件中心，然後觸發器 (Trigger) 根據過濾規則將事件分發給一個或多個目標消費者 (Sink)。\n核心資源 (CRDs):\nSource: 將外部系統的事件導入 Knative 的橋樑。例如，ApiServerSource 可以監聽 Kubernetes API 事件，KafkaSource 可以從 Kafka 主題中拉取訊息。 Broker: 作為事件的匯集中心和訊息通道，接收事件並將其暫存，等待分發。 Trigger: 將 Broker 與事件消費者連接起來，並可以定義過濾規則 (Filter)，只有符合條件的事件才會被傳遞給目標。 Sink: 事件的最終目的地，可以是任何可接收 HTTP 請求的資源，最常見的就是一個 Knative Service。 Knative 與 Kubernetes 的關係 理解它們的關係至關重要：Knative 將 Kubernetes 的能力進行了封裝和簡化。\n當您創建一個 Knative Service 時，Knative 的控制器 (Controller) 會在背景將這個高階定義轉換成一系列底層的 Kubernetes 資源，例如：\nDeployment: 用於管理 Pod。 Service (K8s Service): 用於叢集內部網路。 Ingress: 用於外部流量接入。 HorizontalPodAutoscaler (HPA): 用於標準的 CPU/記憶體擴展。 Knative Pod Autoscaler (KPA): 用於基於請求的擴展。 開發者只需維護一份簡單的 Knative YAML 文件，Knative 就會自動處理這些複雜的底層資源配置和生命週期管理。\nKnative 的依賴與生態 服務網格 (Service Mesh): Knative Serving 的許多進階網路功能（如流量分割）依賴於底層的服務網格，例如 Istio, Linkerd, 或 Contour。Istio 是最常見的選擇。 CI/CD (持續整合/持續部署): Knative 最初的 Build 組件已被獨立出來，發展成為一個更通用的 CI/CD 專案 Tekton。Tekton 專注於在 Kubernetes 上構建、測試和部署應用，與 Knative 能夠完美整合。 總結：為何要用 Knative？ 提升開發者體驗: 將基礎設施複雜性抽象化，讓開發者能更專注於業務邏輯。 極致的成本效益: 「縮容至零」特性確保閒置的應用不消耗任何計算資源。 標準化與可移植性: 基於 Kubernetes，不被任何雲端廠商鎖定，可在任何標準的 K8s 叢集上運行。 強大的事件驅動能力: 為構建現代化的異步、鬆耦合微服務架構提供了堅實的基礎。 總之，Knative 結合了 Serverless 的簡易性、事件驅動的靈活性以及 Kubernetes 的強大功能和可控性，是雲端原生時代下構建現代化應用的理想平台。\n","permalink":"https://yifunlin.github.io/blog/knative/","tags":["Knative","Serverless","K8s","Event-Driven"],"title":"Knative 深度解析：在 Kubernetes 上實現 Serverless"},{"categories":["Kubernetes"],"contents":"今天要分享的是我先前整理的 Kubernetes (K8s) 入門筆記，希望能幫助大家快速上手這個強大的容器編排工具。\nK8s 核心元件 Node: 一個 Node 就是一台實體伺服器或虛擬機，是 K8s 工作負載的運行基礎，可運行一個或多個 Pod。\nPod: K8s 中最小的調度和部署單位。它為一個或多個容器提供了一個共享的運行環境，包含共享的儲存（Volumes）和網路資源。雖然一個 Pod 可以包含多個容器，但通常情況下一個 Pod 只運行一個主容器。\nSidecar: 這是一種將主容器和輔助容器放在同一個 Pod 中的模式。Sidecar 容器用來擴展或增強主容器的功能，例如日誌收集、監控、配置管理等，而不需要修改主應用程式的程式碼。\nService (svc): 將一組 Pod 封裝成一個單一且穩定的服務端點。Service 提供了一個統一的入口來訪問這組 Pod，並具備負載平衡的功能。它可以分為對內的 ClusterIP 服務和對外的 NodePort、LoadBalancer 服務。\nIngress: 作為叢集內服務的對外入口，負責管理從外部訪問叢集內部服務的規則。透過 Ingress，您可以配置不同的 HTTP/HTTPS 路由規則，將外部請求根據域名或路徑轉發到叢集內不同的 Service 上。\nConfigMap 和 Secret: 用於將配置資訊和敏感資料（如密碼、API 金鑰）與應用程式映像檔解耦。這使得配置的修改不需要重新編譯和部署應用程式，提高了靈活性和安全性。\nVolume: 解決了容器內數據持久化的問題。它可以將數據掛載到本地磁碟或遠端儲存空間（如 NFS、Ceph 或雲端儲存），確保即使 Pod 重啟或被刪除，數據依然存在。\nDeployment 和 StatefulSet:\nDeployment: 用於部署和管理「無狀態」應用程式。它能管理 Pod 和 ReplicaSet，並提供副本控制、滾動更新（rolling update）和回滾（rollback）等功能，以實現高可用性。 StatefulSet: 用於部署和管理「有狀態」應用程式（如資料庫）。它能確保 Pod 擁有穩定且唯一的網路標識符和持久化儲存，並保證部署和擴展的順序性。 K8s 架構：Master-Worker K8s 採用 Master-Worker (或稱 Control Plane-Node) 的架構。\nWorker Node (工作節點) 架構 每個 Worker Node 都包含三個核心組件：\nContainer Runtime: 運行容器的基礎軟體，負責拉取容器映像檔、創建、啟動和停止容器。常見的 Runtime 有 Docker、containerd 和 CRI-O。 Kubelet: 每個節點上的代理程式，負責管理該節點上的 Pod，確保容器按照 Pod 的規格（PodSpec）運行。它會定期與 API Server 通信，接收指令並回報節點狀態。 Kube-proxy: 負責為 Service 提供網路代理和負載平衡。它會在每個節點上維護網路規則，將發往 Service 的流量高效地路由到後端正確的 Pod 中。 Master Node (控制平面) 架構 Master Node 是 K8s 叢集的大腦，負責管理和決策，主要由以下四個元件組成：\nkube-apiserver: K8s 的 API 伺服器，是整個叢集的統一入口。所有元件之間的通信都通過 API Server 進行。它負責處理 REST 請求、驗證和處理數據，並將結果存儲到 etcd 中。同時，它也負責認證、授權和訪問控制。\netcd: 一個高可用的鍵值（Key-Value）儲存系統，用於保存整個叢集的所有狀態數據，例如 Pod、Service、Node 的配置和狀態資訊。etcd 是叢集的單一事實來源（single source of truth），是整個系統的數據儲存中心。\nScheduler (調度器): 負責監控新創建的 Pod，並根據資源需求、策略和限制，將它們分配到最合適的 Worker Node 上運行。\nController Manager (控制器管理器): 運行多個控制器進程，這些控制器負責監控叢集狀態，並努力將當前狀態驅動到期望狀態。例如，當一個 Node 故障時，Node Controller 會及時發現並處理；當 Deployment 的副本數不足時，Replication Controller 會啟動新的 Pod。\nCloud Controller Manager (雲端控制器管理器): (可選) 如果您在雲端供應商（如 GCP, AWS, Azure）上運行 K8s，這個組件會負責與雲端平台的 API 進行交互，管理雲端特有的資源，如負載平衡器、儲存卷等。\nDeployment 與 ReplicaSet 的關係 在 K8s 中，我們通常不直接操作 Pod 或 ReplicaSet，而是通過更高層級的 Deployment 來管理。\nDeployment \u0026ndash;(管理)\u0026ndash;\u0026gt; ReplicaSet \u0026ndash;(管理)\u0026ndash;\u0026gt; Pod\nReplicaSet: 確保在任何時候都有指定數量的 Pod 副本在運行。 Deployment: 管理 ReplicaSet 的版本和更新。當您更新 Deployment 的配置時（例如，更新容器映像檔），它會創建一個新的 ReplicaSet，並以滾動更新的方式逐步將 Pod 從舊版本遷移到新版本，實現平滑升級。 我們只需要定義期望的狀態（例如，\u0026ldquo;我需要這個應用程式的3個副本運行最新版本\u0026rdquo;），K8s 就會自動完成所有底層的創建、更新和管理工作。\nService 的其他類型 除了常見的 NodePort，Service 還有其他類型：\nLoadBalancer: 將服務暴露到外部的雲端負載平衡器上，通常在雲端環境中使用。 ExternalName: 將服務通過 CNAME 記錄映射到一個外部域名，用於在叢集內部訪問外部服務。 Headless: 不會分配 ClusterIP，主要用於服務發現，允許您直接解析到後端所有 Pod 的 IP 地址。 K3s \u0026amp; Minikube K3s: 一個輕量級、經過 CNCF 認證的 Kubernetes 發行版，適用於邊緣計算、物聯網和資源受限的環境。 Minikube: 一個可以在本地輕鬆運行單節點 Kubernetes 叢集的工具，非常適合學習和開發測試。 學習資源 30 分鐘 Docker 入門\n這部影片介紹了 Docker 的核心概念，包括它與傳統虛擬機的區別，以及鏡像（Image）、容器（Container）和倉庫（Repository）等關鍵元素。影片還通過一個 Node.js 應用程式實例，演示了如何編寫 Dockerfile、構建鏡像和運行容器，並介紹了 Docker Compose 在多容器應用管理中的應用。 Kubernetes 一小時輕鬆入門\n這部影片旨在幫助初學者快速掌握 K8s 的核心概念和架構，包括 Node、Pod、Service 等。影片詳細介紹了 Master-Worker 架構中各組件的功能，並指導如何使用 Minikube 或 K3s 在本地搭建環境，以及 kubectl 的基本操作。 Ithome 鐵人賽好文：入門 Kubernetes 到考取 CKA 證照\n這是一系列非常詳盡的部落格文章，從基礎概念到實戰操作，內容涵蓋廣泛，是深入學習 K8s 並準備 CKA 認證的絕佳資源。 http://googleusercontent.com/youtube_content/0 http://googleusercontent.com/youtube_content/1\n","permalink":"https://yifunlin.github.io/blog/k8s/","tags":["Kubernetes","K8s","Docker"],"title":"Kubernetes (K8s) 入門筆記"},{"categories":["Talk"],"contents":"演講 訪談內容 雖然那時候才剛加入 LINE 三個月，但很榮幸有這個機會來分享！ 也很榮幸有機會能夠被訪談！\n","permalink":"https://yifunlin.github.io/blog/tech_fresh/","tags":["Design Pattern","Job"],"title":"2025 LINE Tech Fresh 畢業分享會"},{"categories":["AI"],"contents":"簡介： 分享一下，在資工所修課時，所報告的 paper\nMedium 完整版：\nhttps://medium.com/@drose01rrr/masked-attention-mask-transformer-for-universal-image-segmentation-e14f305e433e\n[CV-1] Masked-attention Mask Transformer for Universal Image Segmentation (CVPR 2022) Paper Link Github\n接下來這兩年應該都會在Lab 報完paper後，順便寫個medium來記錄一下 不然我應該很快就忘記之前看過啥啦哈哈哈 Abstract 圖像分割(Image segmentation)就是將pixel 進行分組，會因為分組完的語意差異(eg. category or instance membership 實例歸屬)而產生不同的分割任務。當前的研究仍專注於單一任務就設計一個專用的架構，因此，Meta的研究團隊就提出了一個通用的架構: Mask2Transformer，能應用於任何圖像分割任務(panoptic 全景、instance 實例 or semantic語意)，關鍵就是在於透過改良一般的self-attention機制，將其設計為Mask-attention。透過限制cross-attention 預測的範圍去提取局部特徵，不僅減少了三倍研究的時間，還在四個最熱門的資料集中的表現大幅領現這些專用的架構。 Instance membership: 指的是圖像中每一個物體實例(instance)的唯一識別。eg. 在圖像中，不僅要區分出貓狗的不同，還要區分出相同類別中的不同實例(有兩種品種不同的狗)。意味著即使屬於相同類別，每個instance 仍有自己邊界和標籤\n這邊先來看一下我們的主角Mask2Transformer在各影像分割領域皆大獲全勝呀 Figure 1. State-of-the-art segmentation architectures are typically specialized for each image segmentation task. Although recent work has proposed universal architectures that attempt all tasks and are competitive on semantic and panoptic segmentation, they struggle with segmenting instances. We propose Mask2Former, which, for the first time, outperforms the best specialized architec tures on three studied segmentation tasks on multiple datasets.在三個圖像分割任務（全景、實例和語義分割）中使用了四個流行的數據集（COCO、Cityscapes、ADE20K和Mapillary Vistas）來評估Mask2Former。在這些基準上，我們的通用架構Mask2Former在所有任務上都達到了與專用架構相當或更好的表現。Mask2Former創下了COCO全景分割57.8 PQ、COCO實例分割50.1 AP和ADE20K語義分割57.7 mIoU的最新最先進成果，這些成果均使用相同的架構實現。 Introduction 只因為semantic的不同，導致現在image segmentation又被分成三種不同任務(panoptic、instance or semantic segmentation)，在處理上，也為了他們的不同而個別設計出專用的處理架構 FCNs (Fully Convolutional Networks) 用於 semantic segmentation Mask classification architecture 用於 instance segmentation\n它們雖然在單一領域表現優異，但只要一跨出該領域，表現就會不好。\n缺乏針對其他任務的通用性 所以，第一個通用架構MaskFormer就誕生啦! 比較像是一個「一次做完所有事情」的模型，它會先把圖片分成不同區域，然後對每個區域進行分類和生成遮罩（mask） 能夠用同一個架構處理所有的分割任務（即通用圖像分割） 基於end-to-end 的集合預測目標（例如DETR），並能夠在不修改架構、損失函數或訓練過程的情況下成功應對多個任務 儘管使用通用的架構，但在訓練時仍會針對不同的任務和data set進行各別訓練\nQ: 但為何MaskFromer推出後，最近的工作仍然專注於使用專門單一任務的架構，為何專門單一的架構尚未被通用架構所取代？ A: 儘管MaskFormer足夠靈活，可以應對任何分割任務，但在實際應用中，它們的表現仍然落後於最先進的專門架構。例如: 性能不足: 現有通用架構的最佳報告性能比專門架構的實例分割低9 AP以上 訓練困難: 通常需要更高階的硬體和更長的訓練時間。例如，訓練MaskFormer 需要300個epoch才能達到40.1 AP，而它只能在一個具有32G記憶體的GPU上處理單張圖像\n相比之下，專門的Swin-HTC++只需72個epoch就能達到更好的性能。性能和訓練效率的問題阻礙了通用架構的部署。 第一代被打爆，沒關係 ! 那就來推出第二代啦 之後，Meta 提出了第二代改良版的，提出了一個名為「遮罩注意力遮罩變壓器（Mask2Former）」的通用圖像分割架構，它在不同的分割任務中均優於專門架構，同時在每個任務上仍易於訓練。 我們基於一個簡單的meta architecture，該架構組成包括一個 backbone feature extractor、pixel decoder 和 Transformer decoder Figure 2. Mask2Former overview改良部分:\n在Transformer decoder 中使用 mask-attention\n將注意力限制在圍繞預測分割區域的局部特徵中，這些分割區域可以是對象或區域，具體取決於分組的語義。相較於一般的 Transformer decoder 中使用的cross attention，它會關注圖像中的所有位置，而我們的mask-attention能夠加快收斂速度並改善性能 一般的 Self-attention : 會考慮到每個image結果 (包含後面的)\nMasked Self-attention: 只考慮自己(含)之前的結果\n使用multi-scale high resolution features，有助於模型對小區域進行分割3. 他們提出了優化改進，eg. 交換self attention和cross attention的順序，使query feature 可學習，並移除dropout Cross attention 介紹: 假設輸入是一個special token，經過self-attention後 會得到一組vector，此向量會再乘上一個matrix，得到一個query(這個q:就是decoder產生的) 而Endoer這邊，會先產生出key: k1、k2、k3 這些key會與decoder這邊的query:q 相乘，計算出attention score， 得到alpha 1、2、3，這邊會再做正規化，所以對他用softmax進行正規化後 得到alpha 鋪浪 1、2、3，再與encoder的value相乘，計算出他們的權重 之後再將這些weighted sum相加，得到v，之後再丟入Fully connected network中做處理 一般的Transformer decoder 順序:\nSelf-Attention → Cross-Attention → Feed-Forward Network (FFN)\nSelf-Attention（自注意力）： 首先，Transformer Decoder的每一層會先進行self-attention。這個機制讓decoder的每個查詢位置（query）可以關注到decoder內部其他位置的資訊，從而整合上下文資訊。例如，在語言模型中，這步驟使得句子的每個單詞能夠基於前面已生成的單詞來生成新的單詞 Cross-Attention（交叉注意力）： 完成self-attention後，Decoder會執行cross-attention，這一步是將decoder中的查詢（query）與encoder的輸出（key和value）進行匹配。Cross-attention的作用是將encoder的資訊整合到decoder中，使得decoder可以基於encoder提供的特徵來生成目標序列。例如，在機器翻譯中，這步驟讓decoder能夠根據源語句的編碼來生成目標語句。 Feed-Forward Network（前饋網路）： 最後，經過注意力機制後的特徵會通過一個前饋神經網路（Feed-Forward Network, FFN）進行進一步的非線性轉換和學習。這樣的結構設計能夠提升模型對特徵的表示能力，增強其泛化性能 此篇論文的Transformer decoder 順序: Cross-Attention → Self-Attention → Feed-Forward Network (FFN)\nCross-Attention（交叉注意力）： 首先，decoder中的query features 會與來自 encoder（或pixel decoder）的圖像特徵進行cross-attention。這樣的設計可以讓查詢特徵先從圖像特徵中學習到有用的上下文資訊，形成對物件或區域的初步理解。 Self-Attention（自注意力）： 在cross-attention之後，query features再進行self-attention，這一步讓query features之間能夠互相交互學習，進一步整合資訊，增強查詢特徵的表示能力。這種設計能讓查詢特徵在獲取圖像資訊後進一步自我調整，使模型可以更加專注於圖像中不同區域的細節。 Feed-Forward Network（前饋網路）： 最後，經過cross-attention和self-attention後的查詢特徵會通過一個前饋神經網路（Feed-Forward Network, FFN），進行進一步的非線性轉換和學習。這一步驟進一步強化了查詢特徵的表達能力。 透過 random sample points 計算mask loss，以節省了3倍的訓練記憶體而不影響性能 所有這些改進在不增加計算量的情況下提升了性能，也使得訓練變得更加簡單，讓通用架構對於計算資源有限的用戶更為可及。 Related work 都在比較一些用於單一任務的模型 Specialized semantic segmentation architectures 專用語意分割架構 將任務視為pixel分類問題，FCN-based (全卷積網路)的架構會獨立對每個pixel預測一個類別標籤。 此做法之後被發現對於上下文對於像素分類的精確非常重要，所以後續專注於設計context-module與self-attention variants 來提升精確度 2. Specialized instance segmentation architectures 專用實例分割架構 通常基於mask classification，會預測一組與單一類別標籤相關的binary mask。如Mask R-CNN會從偵測到的bounding boxed產生mask 後續方法專注於\n偵測到更精確的bounding boxed 或 尋找生成動態數量mask的新方法 eg. 使用Dynamic kernels 或 clustering algorithm 雖然任務表現有所提升，但仍缺乏通用性:從一任務跨到另一個任務上應用的話，表現就會不好與靈活性:導致重複研究。 Panoptic segmentation 全景分割 目標是統一 semantic segmentation 與 instance segmentation 任務， 方法: 整合 semantic segmentation 與 instance segmentation 的最佳部分到單一框架中 or 設計一個平等的對待semantic segmentation 與 instance segmentation 的目標架構 全景分割架構的通用性有限，通常只在單一全景任務上表現良好，無法在其他任務中保持一致性能 Universal architectures ETR的出現讓遮罩分類架構具備通用性，可用於各種影像分割任務。 MaskFormer和K-Net等架構擴展了DETR的應用，但在特定任務上仍不如專門模型。 Mask2Former被視為首個在所有分割任務和數據集上超越專門架構表現的通用架構。 Masked-attention Mask Transformer Mask2Former的框架: Backbone: 從 image 中提取最低解析度的特徵 2. Pixel decoder 從backbone 輸出的low-resolution feature 上採樣(upsampling)以生成每個pixel 的 高解析度嵌入 3. Transformer decoder 利用Transformer decoder 來處理影像特徵以處理物件查詢，最終的二元遮罩預測從每像素的嵌入和物件查詢中解碼出來 我們提出的Transformer decoder取代了標準解碼器。我們的Transformer decoder的關鍵在於改採用masked attention ，透過將cross-attention限制在每個查詢的預測遮罩的前景區域內，從而提取局部化特徵，而不是對整個特徵圖進行關注。 為了處理小物體，我們提出了多尺度策略，以利用高解析度特徵。它會依次將pixel decoder的feature pyramid 中的feature map 輸入到Transformer decoder 的 layer 中，並進行輪替(round-robin fashion)處理。最後，我們整合了優化改進，提高了模型性能而不增加額外計算。 3.1 Masked attention 標準Cross-Attention的計算\n此公式可以把它想成一個「訊息聚焦」的過程。每一層的input 其實就是上一層的output，這邊的X_L 代表第L層的輸出特徵，他會累積每一層所產生的訊息，並逐層更新。 這邊會用到 Q: Query、K:Key、V:Value 這三個矩陣，模型會透過Query與key 的相似度計算(就是做內積)，來衡量每個 query 與 不同key 之間的相關性，這時候會得到一組\u0026quot;相似度分數\u0026quot;。 再透過softmax 將這些分數做正規化，讓他們變成attention weight(注意力權重)，這些權重代表模型認為最重要的部分。 這些attention weight 會再與矩陣V相乘，得到加權後的輸出值。最後再與原本的輸入 X_L-1 相加，這就是 residual connection(殘差連接) 。此做法可保留原始訊息，同時又融入新的資訊，讓模型不會忘記前一層的內容。 此公式的重點即是在原本的self-attention 中加入的一個 mask 來控制模型的注意力範圍，讓模型在計算注意力時可以忽略掉不重要的區域。M_L-1 這個矩陣會指定哪些區域需要被關注，這樣模型就能聚焦於真正有用的地方 當M_L-1 = 1時，該位置的值為0，表示此位置應被模型注意到 當M_L-1 = 0時，該位置的值為-無限，這樣softmax計算後會讓該位置的注意力權重變為0，完全忽視這個位置 3.2 High-resolution features High-resolution features 可以提升模型性能，特別是對於小物體的檢測 。然而，使用 High-resolution features 的計算需求非常高。為了在控制計算量的同時又可以引入High-resolution features，論文提出了一種高效率的 multi-scale strategy。論文採用了包含low- and high-resolution fea tures的特徵金字塔（feature pyramid），並在每次只將multi-scale feature 中的其中一個resolution的輸入到Transformer decoder layer。 名詞解釋:\nMulti-Scale Feature (多尺度特徵):\n指從同一張image中提取出不同解析度的特徵表示。從整體影像中提取出不同解析度的特徵圖，形成一個特徵金字塔( Feature Pyramid）。這個Feature Pyramid 中每一層的特徵圖代表不同尺度的影像信息。 例如，在Mask2Former中，像素解碼器會生成1/32、1/16和1/8解析度的特徵圖。這些特徵圖是在不同解析度下進行處理，分別捕捉全局、局部和細節信息，並依次輸入到Transformer解碼器的不同層中。 這樣做的目的是讓模型在處理不同層的特徵時，能同時考慮到大範圍的上下文（低解析度）和小物體的細節（高解析度）\n優化版的self-attention: 更換self-attention和cross-attention的順序：為了讓計算更有效，我們將self-attention和cross-attention的順序調換（即我們的新「masked attention」）。最初進入第一個self-attention層的查詢特徵是與影像無關的，並未包含來自影像的信號，因此此時應用self-attention無法有效增加信息。\n使查詢特徵（X0​）變為可學習：我們使查詢特徵本身變為可學習（同時保留可學習的查詢位置嵌入），並且這些可學習的查詢特徵在用於Transformer解碼器進行遮罩預測（M0）之前會直接受到監督。我們發現這些可學習的查詢特徵類似於區域候選網路（Region Proposal Network, RPN），能夠產生遮罩候選。 移除dropout：我們發現dropout並非必要，且通常會降低性能。因此，我們在解碼器中完全移除了dropout。 3.3. Improving training efficiency 由於 High-resolution mask prediction 會占用大量memory。 eg. MaskFormer 僅能在32G記憶體的GPU中容納單一張影像 於是我們可以改透過隨機抽取k個點去計算其mask loss，而不需要計算整個mask loss，所以此篇論文在 matching 和 final loss計算中都使用這種random sampled points 的方式去計算mask loss。 Mask2Former透過此抽樣策略降低了計算需求，具體做法如下： 匹配損失中的統一抽樣：在構建代價矩陣時，對所有預測和真實遮罩使用相同的 K=12544K = 12544K=12544 個抽樣點，以減少計算量。 最終損失中的不同抽樣：在已配對的預測和真實遮罩之間的最終損失計算中，使用不同的抽樣點集合，並採用重要性抽樣來更精確地計算損失。 這種策略有效地將訓練記憶體需求從18GB降至6GB，使Mask2Former在有限的計算資源下也能運行。 Experiments Implement details:\n這邊是他們loss function的設計，使用了兩種Loss function，分別是binary cross entropy、dice loss，整體的mask loss (Lmask) formula如圖所示: lambda ce、dice代表權重 Lce代表cross entropy 的loss Ldice 代表dice的loss\n這邊是作者實驗得出的，權重係數都帶5\nTraining settings 先前有提到，即便是這種通用的架構，訓練時仍要個別訓練，所以論文就針對image segmentation 的各個類別去分別進行訓練\nPanoptic and Instance Segmentation 使用 Detectron2 框架，並遵循更新的 Mask R-CNN 基準設置，針對 COCO 資料集進行訓練 Optimizer：使用 AdamW和 調整 learning rate Initial learning rate：設為 0.0001。 Weight decay：所有 backbone 設為 0.05。 learning rate調整：在backbone 上 Learning rate * 0.1、在training step 的 90% 和 95% 處將learning rate衰減 10 倍。 epoch 和 batch size：預設模型訓練 50 個 epoch，批次大小為 16。 數據擴增：使用 Large-Scale Jittering( LSJ），隨機縮放範圍從 0.1 到 2.0，裁切大小固定:1024×1024 推理設置：採用標準 Mask R-CNN 推理設置，將圖像短邊縮放至 800，長邊最大為 1333。 計算 FLOPs 和 fps： FLOPs 是基於 100 張驗證圖像（不同大小的 COCO 圖像）平均計算。 每秒幀數（fps）是在 V100 GPU 上測量，批次大小為 1，取整個驗證集的平均運行時間（包括後處理時間）。\n語義分割（Semantic Segmentation） Semantic Segmentation 訓練設置上有些微差異，大多都遵循前面的設定，但有以下例外：\n學習率乘數：0.1 的學習率乘數應用於 CNN 和 Transformer 的骨幹網路，而非僅應用於 CNN 骨幹網路。 ResNet 和 Swin 骨幹：初始學習率設為 0.0001，權重衰減設為 0.05，而不是使用不同的學習率。\nResults Mask2Former的實驗部分展示了其在影像分割任務中的有效性 比較對象與數據集：\n比較：Mask2Former被與最先進的專門影像分割模型進行了對比，包括DETR、Mask R-CNN、K-Net等模型。 數據集：使用了四個常見的影像分割數據集：COCO、ADE20K、Cityscapes和Mapillary Vistas，這些數據集包含了語義分割、實例分割和全景分割任務。\n評估指標： PQ (Panoptic Quality)：用於全景分割的指標。 APTh (Average Precision)：針對實例分割任務的「事物」類別的精確度。 mIoU (Mean Intersection over Union)：語義分割的標準指標，用於衡量模型在不同分割類別上的精度。\n主要結果： 全景分割：\n在COCO數據集上，Mask2Former的表現超越了現有的模型，尤其是Swin-L的版本，PQ提升了5.1。這表明Mask2Former在不同骨幹網路上的表現均優於MaskFormer，且收斂速度更快。\n實例分割：在COCO數據集上，Mask2Former使用較少的訓練迭代次數就超越了Mask R-CNN基線，並且在邊界AP（Boundary AP）上也取得了更高的性能，說明其遮罩預測在邊界上更加精細。 4. 消融實驗（Ablation Study）：\nMasked Attention與高解析度特徵：移除masked attention或高解析度特徵會導致性能顯著下降，表明這些組件對於模型的性能提升至關重要。\n實驗: 移除masked attention或高解析度特徵\n-\u0026gt; 導致性能顯著下降 =\u0026gt; 表明這些組件對於模型的性能提升很重要 ! 切換self-attention和cross-attention的順序、引入可學習(Learnable Queries)的查詢特徵並移除dropout:\n=\u0026gt; 均對性能有輕微提升，且不增加額外的計算量 不同的Pixel Decoder：MSDeformAttn(multi-scale de-formable attention Transformer) 在所有任務上表現最佳，表明其作為像素解碼器在各種分割任務中具有通用性。\n記憶體優化： 通過抽樣點而不是整個遮罩來計算損失，將訓練過程的記憶體需求從18GB減少到6GB，同時保持性能不變。這一策略降低了計算資源需求，使得Mask2Former對於記憶體受限的環境更友好。\n泛化能力： Mask2Former在不同數據集上的表現均優異，展示了其作為通用影像分割模型的潛力，可用於多種影像分割任務。\n限制： Mask2Former雖然在多個任務上泛化良好，但仍然需要針對特定任務進行專門訓練。此外，模型在小物體分割上仍有改進空間，未能充分利用多尺度特徵。\n總結來說，Mask2Former在影像分割的主要任務上展現了良好的效果，並且通過多項創新設計提高了性能，減少了計算資源需求，但仍有進一步改進的空間。 Conclusion Meta 提出了通用圖像分割的Mask2Former。基於一個簡單的元框架，改使用mask-attention的Transformer decoder Mask2Former在四個流行的數據集上（COCO、Cityscapes、ADE20K和Mapillary Vistas），在全景分割、實例分割和語義分割三大圖像分割任務中都取得了最佳成績，已超越了每個任務所專用的模型，且易於訓練 與每個任務所專用的模型，Mask2Former節省了三倍的研究精力，對運算資源有限的用戶也十分友善\n","permalink":"https://yifunlin.github.io/blog/mask_transformer/","tags":["Computer Visions"],"title":"Masked-attention Mask Transformer for Universal Image Segmentation (CVPR 2022)"},{"categories":["技術分享"],"contents":"簡介： LINE Bot 建立完整教學：\nhttps://medium.com/@drose01rrr/2024-line-bot-%E5%89%B5%E5%BB%BA%E6%AD%A5%E9%A9%9F-589227edd42c\n","permalink":"https://yifunlin.github.io/blog/line_bot/","tags":null,"title":"LINE Bot 建立 - 完整教學"},{"categories":["Blockchain"],"contents":"簡介： ","permalink":"https://yifunlin.github.io/blog/blockchain/","tags":null,"title":"Blockchain 研究"},{"categories":["AI"],"contents":"簡介： 在這邊跟大家分享一下，我在 2024 年去比 IThome 鐵人賽，連續 30 天產出的文章！\nhttps://ithelp.ithome.com.tw/users/20168537/ironman/7263\n","permalink":"https://yifunlin.github.io/blog/ithome_rag/","tags":["GAI"],"title":"[2024 IThome 鐵人賽]LLM 應用、開發框架、RAG優化及評估方法系列 - GAI 爆炸時代 "},{"categories":["技術分享"],"contents":"簡介： 有些老師都不開放PPT下載，這樣要怎麼做筆記呢！來教大家如何在 Tronclass 下載未開放的檔案與影片\n","permalink":"https://yifunlin.github.io/blog/tronclass/","tags":null,"title":"Tronclass下載未開放的檔案與影片"}]